{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P0MfOtYdOgY0"
   },
   "source": [
    " ## Bag of Words model is used to preprocess the text by converting it into a bag of words, which keeps a count of the total occurrences of most frequently used words.\n",
    " \n",
    " 1. Why to use Bag of Words Model?\n",
    " \n",
    " A: Whenever we apply any algorithm in NLP, it works on numbers. We cannot directly feed our text into that algorithm. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4QZEJWIEOW1S"
   },
   "outputs": [],
   "source": [
    "text = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.Contrary to popular belief, Lorem Ipsum is not simply random text. It has roots in a piece of classical Latin literature from 45 BC, making it over 2000 years old. Richard McClintock, a Latin professor at Hampden-Sydney College in Virginia, looked up one of the more obscure Latin words, consectetur, from a Lorem Ipsum passage, and going through the cites of the word in classical literature, discovered the undoubtable source. Lorem Ipsum comes from sections 1.10.32 and 1.10.33 of \"de Finibus Bonorum et Malorum\" (The Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a treatise on the theory of ethics, very popular during the Renaissance. The first line of Lorem Ipsum, \"Lorem ipsum dolor sit amet..\", comes from a line in section 1.10.32.\n",
    "\n",
    "The standard chunk of Lorem Ipsum used since the 1500s is reproduced below for those interested. Sections 1.10.32 and 1.10.33 from \"de Finibus Bonorum et Malorum\" by Cicero are also reproduced in their exact original form, accompanied by English versions from the 1914 translation by H. Rackham.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wJmNMJeCPoOA"
   },
   "source": [
    "**Step 1 :** We will first preprocess the data, in order to:\n",
    "\n",
    "- Convert text to lower case.\n",
    "- Remove all non-alpha numeric characters.\n",
    "- Remove all punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kvissa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# Bag of Words\n",
    "# 1. Convert the text into Sentences\n",
    "# 2. Extract the unique words\n",
    "# 3. Consturct a data frame where each word as a column. and each sentence as a row.\n",
    "# 4. the data frame contains for a specific column 0 or 1 depending on whether it appeared in the sentence or not.\n",
    "sentences = sent_tokenize(text)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lorem ipsum is simply dummy text of the printing and typesetting industry ',\n",
       " 'lorem ipsum has been the industry s standard dummy text ever since the 1500s when an unknown printer took a galley of type and scrambled it to make a type specimen book ',\n",
       " 'it has survived not only five centuries but also the leap into electronic typesetting remaining essentially unchanged ',\n",
       " 'it was popularised in the 1960s with the release of letraset sheets containing lorem ipsum passages and more recently with desktop publishing software like aldus pagemaker including versions of lorem ipsum contrary to popular belief lorem ipsum is not simply random text ',\n",
       " 'it has roots in a piece of classical latin literature from 45 bc making it over 2000 years old ',\n",
       " 'richard mcclintock a latin professor at hampden sydney college in virginia looked up one of the more obscure latin words consectetur from a lorem ipsum passage and going through the cites of the word in classical literature discovered the undoubtable source ',\n",
       " 'lorem ipsum comes from sections 1 10 32 and 1 10 33 of de finibus bonorum et malorum the extremes of good and evil by cicero written in 45 bc ',\n",
       " 'this book is a treatise on the theory of ethics very popular during the renaissance ',\n",
       " 'the first line of lorem ipsum lorem ipsum dolor sit amet comes from a line in section 1 10 32 ',\n",
       " 'the standard chunk of lorem ipsum used since the 1500s is reproduced below for those interested ',\n",
       " 'sections 1 10 32 and 1 10 33 from de finibus bonorum et malorum by cicero are also reproduced in their exact original form accompanied by english versions from the 1914 translation by h rackham ']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_preprocessed = []\n",
    "for sentence in sentences:\n",
    "    sentence = sentence.lower()\n",
    "    res = re.sub(r'[\\W]', ' ', sentence)\n",
    "    res = re.sub(r'\\s+',' ', res)\n",
    "    sent_preprocessed.append(res)\n",
    "\n",
    "sent_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2d6Tm39GQNe0"
   },
   "source": [
    "**Step 2** : Obtaining most frequent words in our text.\n",
    "\n",
    "- We declare a dictionary to hold our bag of words.\n",
    "- Next we tokenize each sentence to words.\n",
    "- Now for each word in sentence, we check if the word exists in our dictionary.\n",
    "- If it does, then we increment its count by 1. If it doesn’t, we add it to our dictionary and set its count as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FB7Gw07Yow9q"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lorem': 10,\n",
       " 'ipsum': 10,\n",
       " 'is': 4,\n",
       " 'simply': 2,\n",
       " 'dummy': 2,\n",
       " 'text': 3,\n",
       " 'of': 12,\n",
       " 'the': 17,\n",
       " 'printing': 1,\n",
       " 'and': 7,\n",
       " 'typesetting': 2,\n",
       " 'industry': 2,\n",
       " 'has': 3,\n",
       " 'been': 1,\n",
       " 's': 1,\n",
       " 'standard': 2,\n",
       " 'ever': 1,\n",
       " 'since': 2,\n",
       " '1500s': 2,\n",
       " 'when': 1,\n",
       " 'an': 1,\n",
       " 'unknown': 1,\n",
       " 'printer': 1,\n",
       " 'took': 1,\n",
       " 'a': 7,\n",
       " 'galley': 1,\n",
       " 'type': 2,\n",
       " 'scrambled': 1,\n",
       " 'it': 5,\n",
       " 'to': 2,\n",
       " 'make': 1,\n",
       " 'specimen': 1,\n",
       " 'book': 2,\n",
       " 'survived': 1,\n",
       " 'not': 2,\n",
       " 'only': 1,\n",
       " 'five': 1,\n",
       " 'centuries': 1,\n",
       " 'but': 1,\n",
       " 'also': 2,\n",
       " 'leap': 1,\n",
       " 'into': 1,\n",
       " 'electronic': 1,\n",
       " 'remaining': 1,\n",
       " 'essentially': 1,\n",
       " 'unchanged': 1,\n",
       " 'was': 1,\n",
       " 'popularised': 1,\n",
       " 'in': 7,\n",
       " '1960s': 1,\n",
       " 'with': 2,\n",
       " 'release': 1,\n",
       " 'letraset': 1,\n",
       " 'sheets': 1,\n",
       " 'containing': 1,\n",
       " 'passages': 1,\n",
       " 'more': 2,\n",
       " 'recently': 1,\n",
       " 'desktop': 1,\n",
       " 'publishing': 1,\n",
       " 'software': 1,\n",
       " 'like': 1,\n",
       " 'aldus': 1,\n",
       " 'pagemaker': 1,\n",
       " 'including': 1,\n",
       " 'versions': 2,\n",
       " 'contrary': 1,\n",
       " 'popular': 2,\n",
       " 'belief': 1,\n",
       " 'random': 1,\n",
       " 'roots': 1,\n",
       " 'piece': 1,\n",
       " 'classical': 2,\n",
       " 'latin': 3,\n",
       " 'literature': 2,\n",
       " 'from': 6,\n",
       " '45': 2,\n",
       " 'bc': 2,\n",
       " 'making': 1,\n",
       " 'over': 1,\n",
       " '2000': 1,\n",
       " 'years': 1,\n",
       " 'old': 1,\n",
       " 'richard': 1,\n",
       " 'mcclintock': 1,\n",
       " 'professor': 1,\n",
       " 'at': 1,\n",
       " 'hampden': 1,\n",
       " 'sydney': 1,\n",
       " 'college': 1,\n",
       " 'virginia': 1,\n",
       " 'looked': 1,\n",
       " 'up': 1,\n",
       " 'one': 1,\n",
       " 'obscure': 1,\n",
       " 'words': 1,\n",
       " 'consectetur': 1,\n",
       " 'passage': 1,\n",
       " 'going': 1,\n",
       " 'through': 1,\n",
       " 'cites': 1,\n",
       " 'word': 1,\n",
       " 'discovered': 1,\n",
       " 'undoubtable': 1,\n",
       " 'source': 1,\n",
       " 'comes': 2,\n",
       " 'sections': 2,\n",
       " '1': 5,\n",
       " '10': 5,\n",
       " '32': 3,\n",
       " '33': 2,\n",
       " 'de': 2,\n",
       " 'finibus': 2,\n",
       " 'bonorum': 2,\n",
       " 'et': 2,\n",
       " 'malorum': 2,\n",
       " 'extremes': 1,\n",
       " 'good': 1,\n",
       " 'evil': 1,\n",
       " 'by': 4,\n",
       " 'cicero': 2,\n",
       " 'written': 1,\n",
       " 'this': 1,\n",
       " 'treatise': 1,\n",
       " 'on': 1,\n",
       " 'theory': 1,\n",
       " 'ethics': 1,\n",
       " 'very': 1,\n",
       " 'during': 1,\n",
       " 'renaissance': 1,\n",
       " 'first': 1,\n",
       " 'line': 2,\n",
       " 'dolor': 1,\n",
       " 'sit': 1,\n",
       " 'amet': 1,\n",
       " 'section': 1,\n",
       " 'chunk': 1,\n",
       " 'used': 1,\n",
       " 'reproduced': 2,\n",
       " 'below': 1,\n",
       " 'for': 1,\n",
       " 'those': 1,\n",
       " 'interested': 1,\n",
       " 'are': 1,\n",
       " 'their': 1,\n",
       " 'exact': 1,\n",
       " 'original': 1,\n",
       " 'form': 1,\n",
       " 'accompanied': 1,\n",
       " 'english': 1,\n",
       " '1914': 1,\n",
       " 'translation': 1,\n",
       " 'h': 1,\n",
       " 'rackham': 1}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict = {}\n",
    "for sentence in sent_preprocessed:\n",
    "    for word in word_tokenize(sentence):\n",
    "        if word not in word_dict.keys():\n",
    "            word_dict.update({word: 1})\n",
    "        else:\n",
    "            word_dict.update({word: word_dict[word] + 1})\n",
    "\n",
    "word_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3XsM1uhMRC5-"
   },
   "source": [
    "**Step 3** : Building the Bag of Words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Iwsn9H_oxtn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "vector = []\n",
    "for sent in sent_preprocessed:\n",
    "    row = []\n",
    "    words_in_sentence = word_tokenize(sent)\n",
    "    for word in word_dict.keys():\n",
    "        if word in words_in_sentence:\n",
    "            row.append(1)\n",
    "        else:\n",
    "            row.append(0)\n",
    "    vector.append(row)\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lorem</th>\n",
       "      <th>ipsum</th>\n",
       "      <th>is</th>\n",
       "      <th>simply</th>\n",
       "      <th>dummy</th>\n",
       "      <th>text</th>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <th>printing</th>\n",
       "      <th>and</th>\n",
       "      <th>...</th>\n",
       "      <th>their</th>\n",
       "      <th>exact</th>\n",
       "      <th>original</th>\n",
       "      <th>form</th>\n",
       "      <th>accompanied</th>\n",
       "      <th>english</th>\n",
       "      <th>1914</th>\n",
       "      <th>translation</th>\n",
       "      <th>h</th>\n",
       "      <th>rackham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lorem  ipsum  is  simply  dummy  text  of  the  printing  and  ...  their  \\\n",
       "0      1      1   1       1      1     1   1    1         1    1  ...      0   \n",
       "1      1      1   0       0      1     1   1    1         0    1  ...      0   \n",
       "2      0      0   0       0      0     0   0    1         0    0  ...      0   \n",
       "3      1      1   1       1      0     1   1    1         0    1  ...      0   \n",
       "4      0      0   0       0      0     0   1    0         0    0  ...      0   \n",
       "\n",
       "   exact  original  form  accompanied  english  1914  translation  h  rackham  \n",
       "0      0         0     0            0        0     0            0  0        0  \n",
       "1      0         0     0            0        0     0            0  0        0  \n",
       "2      0         0     0            0        0     0            0  0        0  \n",
       "3      0         0     0            0        0     0            0  0        0  \n",
       "4      0         0     0            0        0     0            0  0        0  \n",
       "\n",
       "[5 rows x 154 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(vector, columns = word_dict.keys())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b60x_O_Gfz2b"
   },
   "source": [
    "# TF - IDF\n",
    "\n",
    "TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).\n",
    "\n",
    "\n",
    "IDF(t) = $\\log_e (N/n)$\n",
    "\n",
    "where,\n",
    "-      N = Total number of documents,\n",
    "-      n = Number of documents with term t in it\n",
    "\n",
    "So TF * IDF will give the output about a single term t\n",
    "\n",
    "> Document means sentence\n",
    "\n",
    "> The whole text is called as Corpus\n",
    "\n",
    "TF - Term Frequency\n",
    "\n",
    "IDF- Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C8eJxSMRoyU6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.17710846, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.20169137, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.26171954, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.27601752, 0.        , 0.18359144, ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "x_tf = tfidf.fit_transform(sent_preprocessed).toarray()\n",
    "x_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 150)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " '1500s',\n",
       " '1914',\n",
       " '1960s',\n",
       " '2000',\n",
       " '32',\n",
       " '33',\n",
       " '45',\n",
       " 'accompanied',\n",
       " 'aldus',\n",
       " 'also',\n",
       " 'amet',\n",
       " 'an',\n",
       " 'and',\n",
       " 'are',\n",
       " 'at',\n",
       " 'bc',\n",
       " 'been',\n",
       " 'belief',\n",
       " 'below',\n",
       " 'bonorum',\n",
       " 'book',\n",
       " 'but',\n",
       " 'by',\n",
       " 'centuries',\n",
       " 'chunk',\n",
       " 'cicero',\n",
       " 'cites',\n",
       " 'classical',\n",
       " 'college',\n",
       " 'comes',\n",
       " 'consectetur',\n",
       " 'containing',\n",
       " 'contrary',\n",
       " 'de',\n",
       " 'desktop',\n",
       " 'discovered',\n",
       " 'dolor',\n",
       " 'dummy',\n",
       " 'during',\n",
       " 'electronic',\n",
       " 'english',\n",
       " 'essentially',\n",
       " 'et',\n",
       " 'ethics',\n",
       " 'ever',\n",
       " 'evil',\n",
       " 'exact',\n",
       " 'extremes',\n",
       " 'finibus',\n",
       " 'first',\n",
       " 'five',\n",
       " 'for',\n",
       " 'form',\n",
       " 'from',\n",
       " 'galley',\n",
       " 'going',\n",
       " 'good',\n",
       " 'hampden',\n",
       " 'has',\n",
       " 'in',\n",
       " 'including',\n",
       " 'industry',\n",
       " 'interested',\n",
       " 'into',\n",
       " 'ipsum',\n",
       " 'is',\n",
       " 'it',\n",
       " 'latin',\n",
       " 'leap',\n",
       " 'letraset',\n",
       " 'like',\n",
       " 'line',\n",
       " 'literature',\n",
       " 'looked',\n",
       " 'lorem',\n",
       " 'make',\n",
       " 'making',\n",
       " 'malorum',\n",
       " 'mcclintock',\n",
       " 'more',\n",
       " 'not',\n",
       " 'obscure',\n",
       " 'of',\n",
       " 'old',\n",
       " 'on',\n",
       " 'one',\n",
       " 'only',\n",
       " 'original',\n",
       " 'over',\n",
       " 'pagemaker',\n",
       " 'passage',\n",
       " 'passages',\n",
       " 'piece',\n",
       " 'popular',\n",
       " 'popularised',\n",
       " 'printer',\n",
       " 'printing',\n",
       " 'professor',\n",
       " 'publishing',\n",
       " 'rackham',\n",
       " 'random',\n",
       " 'recently',\n",
       " 'release',\n",
       " 'remaining',\n",
       " 'renaissance',\n",
       " 'reproduced',\n",
       " 'richard',\n",
       " 'roots',\n",
       " 'scrambled',\n",
       " 'section',\n",
       " 'sections',\n",
       " 'sheets',\n",
       " 'simply',\n",
       " 'since',\n",
       " 'sit',\n",
       " 'software',\n",
       " 'source',\n",
       " 'specimen',\n",
       " 'standard',\n",
       " 'survived',\n",
       " 'sydney',\n",
       " 'text',\n",
       " 'the',\n",
       " 'their',\n",
       " 'theory',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'took',\n",
       " 'translation',\n",
       " 'treatise',\n",
       " 'type',\n",
       " 'typesetting',\n",
       " 'unchanged',\n",
       " 'undoubtable',\n",
       " 'unknown',\n",
       " 'up',\n",
       " 'used',\n",
       " 'versions',\n",
       " 'very',\n",
       " 'virginia',\n",
       " 'was',\n",
       " 'when',\n",
       " 'with',\n",
       " 'word',\n",
       " 'words',\n",
       " 'written',\n",
       " 'years']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_feature_names() # unique words or column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>1500s</th>\n",
       "      <th>1914</th>\n",
       "      <th>1960s</th>\n",
       "      <th>2000</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>45</th>\n",
       "      <th>accompanied</th>\n",
       "      <th>aldus</th>\n",
       "      <th>...</th>\n",
       "      <th>versions</th>\n",
       "      <th>very</th>\n",
       "      <th>virginia</th>\n",
       "      <th>was</th>\n",
       "      <th>when</th>\n",
       "      <th>with</th>\n",
       "      <th>word</th>\n",
       "      <th>words</th>\n",
       "      <th>written</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.168204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.168204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.168204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.336408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.229477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.268468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175004</td>\n",
       "      <td>0.175004</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.346225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173113</td>\n",
       "      <td>0.196843</td>\n",
       "      <td>0.196843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.23029</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.201691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.201691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.276018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138009</td>\n",
       "      <td>0.156927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          10     1500s      1914     1960s      2000        32        33  \\\n",
       "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1   0.000000  0.177108  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3   0.000000  0.000000  0.000000  0.168204  0.000000  0.000000  0.000000   \n",
       "4   0.000000  0.000000  0.000000  0.000000  0.268468  0.000000  0.000000   \n",
       "5   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "6   0.346225  0.000000  0.000000  0.000000  0.000000  0.173113  0.196843   \n",
       "7   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "8   0.201691  0.000000  0.000000  0.000000  0.000000  0.201691  0.000000   \n",
       "9   0.000000  0.261720  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "10  0.276018  0.000000  0.183591  0.000000  0.000000  0.138009  0.156927   \n",
       "\n",
       "          45  accompanied     aldus  ...  versions      very  virginia  \\\n",
       "0   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "1   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "2   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "3   0.000000     0.000000  0.168204  ...  0.143774  0.000000  0.000000   \n",
       "4   0.229477     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "5   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.175004   \n",
       "6   0.196843     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "7   0.000000     0.000000  0.000000  ...  0.000000  0.305733  0.000000   \n",
       "8   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "9   0.000000     0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "10  0.000000     0.183591  0.000000  ...  0.156927  0.000000  0.000000   \n",
       "\n",
       "         was      when      with      word     words  written     years  \n",
       "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "1   0.000000  0.207202  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "3   0.168204  0.000000  0.336408  0.000000  0.000000  0.00000  0.000000  \n",
       "4   0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.268468  \n",
       "5   0.000000  0.000000  0.000000  0.175004  0.175004  0.00000  0.000000  \n",
       "6   0.000000  0.000000  0.000000  0.000000  0.000000  0.23029  0.000000  \n",
       "7   0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "8   0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "10  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  \n",
       "\n",
       "[11 rows x 150 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x_tf, columns = tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hlqrm_vfosdX"
   },
   "source": [
    "# Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m4CZRD2Uoy8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 150)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "x_cv = cv.fit_transform(sent_preprocessed).toarray()\n",
    "x_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " '1500s',\n",
       " '1914',\n",
       " '1960s',\n",
       " '2000',\n",
       " '32',\n",
       " '33',\n",
       " '45',\n",
       " 'accompanied',\n",
       " 'aldus',\n",
       " 'also',\n",
       " 'amet',\n",
       " 'an',\n",
       " 'and',\n",
       " 'are',\n",
       " 'at',\n",
       " 'bc',\n",
       " 'been',\n",
       " 'belief',\n",
       " 'below',\n",
       " 'bonorum',\n",
       " 'book',\n",
       " 'but',\n",
       " 'by',\n",
       " 'centuries',\n",
       " 'chunk',\n",
       " 'cicero',\n",
       " 'cites',\n",
       " 'classical',\n",
       " 'college',\n",
       " 'comes',\n",
       " 'consectetur',\n",
       " 'containing',\n",
       " 'contrary',\n",
       " 'de',\n",
       " 'desktop',\n",
       " 'discovered',\n",
       " 'dolor',\n",
       " 'dummy',\n",
       " 'during',\n",
       " 'electronic',\n",
       " 'english',\n",
       " 'essentially',\n",
       " 'et',\n",
       " 'ethics',\n",
       " 'ever',\n",
       " 'evil',\n",
       " 'exact',\n",
       " 'extremes',\n",
       " 'finibus',\n",
       " 'first',\n",
       " 'five',\n",
       " 'for',\n",
       " 'form',\n",
       " 'from',\n",
       " 'galley',\n",
       " 'going',\n",
       " 'good',\n",
       " 'hampden',\n",
       " 'has',\n",
       " 'in',\n",
       " 'including',\n",
       " 'industry',\n",
       " 'interested',\n",
       " 'into',\n",
       " 'ipsum',\n",
       " 'is',\n",
       " 'it',\n",
       " 'latin',\n",
       " 'leap',\n",
       " 'letraset',\n",
       " 'like',\n",
       " 'line',\n",
       " 'literature',\n",
       " 'looked',\n",
       " 'lorem',\n",
       " 'make',\n",
       " 'making',\n",
       " 'malorum',\n",
       " 'mcclintock',\n",
       " 'more',\n",
       " 'not',\n",
       " 'obscure',\n",
       " 'of',\n",
       " 'old',\n",
       " 'on',\n",
       " 'one',\n",
       " 'only',\n",
       " 'original',\n",
       " 'over',\n",
       " 'pagemaker',\n",
       " 'passage',\n",
       " 'passages',\n",
       " 'piece',\n",
       " 'popular',\n",
       " 'popularised',\n",
       " 'printer',\n",
       " 'printing',\n",
       " 'professor',\n",
       " 'publishing',\n",
       " 'rackham',\n",
       " 'random',\n",
       " 'recently',\n",
       " 'release',\n",
       " 'remaining',\n",
       " 'renaissance',\n",
       " 'reproduced',\n",
       " 'richard',\n",
       " 'roots',\n",
       " 'scrambled',\n",
       " 'section',\n",
       " 'sections',\n",
       " 'sheets',\n",
       " 'simply',\n",
       " 'since',\n",
       " 'sit',\n",
       " 'software',\n",
       " 'source',\n",
       " 'specimen',\n",
       " 'standard',\n",
       " 'survived',\n",
       " 'sydney',\n",
       " 'text',\n",
       " 'the',\n",
       " 'their',\n",
       " 'theory',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'took',\n",
       " 'translation',\n",
       " 'treatise',\n",
       " 'type',\n",
       " 'typesetting',\n",
       " 'unchanged',\n",
       " 'undoubtable',\n",
       " 'unknown',\n",
       " 'up',\n",
       " 'used',\n",
       " 'versions',\n",
       " 'very',\n",
       " 'virginia',\n",
       " 'was',\n",
       " 'when',\n",
       " 'with',\n",
       " 'word',\n",
       " 'words',\n",
       " 'written',\n",
       " 'years']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>1500s</th>\n",
       "      <th>1914</th>\n",
       "      <th>1960s</th>\n",
       "      <th>2000</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>45</th>\n",
       "      <th>accompanied</th>\n",
       "      <th>aldus</th>\n",
       "      <th>...</th>\n",
       "      <th>versions</th>\n",
       "      <th>very</th>\n",
       "      <th>virginia</th>\n",
       "      <th>was</th>\n",
       "      <th>when</th>\n",
       "      <th>with</th>\n",
       "      <th>word</th>\n",
       "      <th>words</th>\n",
       "      <th>written</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    10  1500s  1914  1960s  2000  32  33  45  accompanied  aldus  ...  \\\n",
       "0    0      0     0      0     0   0   0   0            0      0  ...   \n",
       "1    0      1     0      0     0   0   0   0            0      0  ...   \n",
       "2    0      0     0      0     0   0   0   0            0      0  ...   \n",
       "3    0      0     0      1     0   0   0   0            0      1  ...   \n",
       "4    0      0     0      0     1   0   0   1            0      0  ...   \n",
       "5    0      0     0      0     0   0   0   0            0      0  ...   \n",
       "6    2      0     0      0     0   1   1   1            0      0  ...   \n",
       "7    0      0     0      0     0   0   0   0            0      0  ...   \n",
       "8    1      0     0      0     0   1   0   0            0      0  ...   \n",
       "9    0      1     0      0     0   0   0   0            0      0  ...   \n",
       "10   2      0     1      0     0   1   1   0            1      0  ...   \n",
       "\n",
       "    versions  very  virginia  was  when  with  word  words  written  years  \n",
       "0          0     0         0    0     0     0     0      0        0      0  \n",
       "1          0     0         0    0     1     0     0      0        0      0  \n",
       "2          0     0         0    0     0     0     0      0        0      0  \n",
       "3          1     0         0    1     0     2     0      0        0      0  \n",
       "4          0     0         0    0     0     0     0      0        0      1  \n",
       "5          0     0         1    0     0     0     1      1        0      0  \n",
       "6          0     0         0    0     0     0     0      0        1      0  \n",
       "7          0     1         0    0     0     0     0      0        0      0  \n",
       "8          0     0         0    0     0     0     0      0        0      0  \n",
       "9          0     0         0    0     0     0     0      0        0      0  \n",
       "10         1     0         0    0     0     0     0      0        0      0  \n",
       "\n",
       "[11 rows x 150 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x_cv, columns = cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lorem ipsum is simply dummy text of the printing and typesetting industry ',\n",
       " 'lorem ipsum has been the industry s standard dummy text ever since the 1500s when an unknown printer took a galley of type and scrambled it to make a type specimen book ',\n",
       " 'it has survived not only five centuries but also the leap into electronic typesetting remaining essentially unchanged ',\n",
       " 'it was popularised in the 1960s with the release of letraset sheets containing lorem ipsum passages and more recently with desktop publishing software like aldus pagemaker including versions of lorem ipsum contrary to popular belief lorem ipsum is not simply random text ',\n",
       " 'it has roots in a piece of classical latin literature from 45 bc making it over 2000 years old ',\n",
       " 'richard mcclintock a latin professor at hampden sydney college in virginia looked up one of the more obscure latin words consectetur from a lorem ipsum passage and going through the cites of the word in classical literature discovered the undoubtable source ',\n",
       " 'lorem ipsum comes from sections 1 10 32 and 1 10 33 of de finibus bonorum et malorum the extremes of good and evil by cicero written in 45 bc ',\n",
       " 'this book is a treatise on the theory of ethics very popular during the renaissance ',\n",
       " 'the first line of lorem ipsum lorem ipsum dolor sit amet comes from a line in section 1 10 32 ',\n",
       " 'the standard chunk of lorem ipsum used since the 1500s is reproduced below for those interested ',\n",
       " 'sections 1 10 32 and 1 10 33 from de finibus bonorum et malorum by cicero are also reproduced in their exact original form accompanied by english versions from the 1914 translation by h rackham ']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Batch 45 NLP -  Word Embedding - Bag of Words and TF IDF model.ipynb",
   "provenance": [
    {
     "file_id": "1MqV4aDREeCNrRCQf_PSff8c4Nrq2zwNW",
     "timestamp": 1583923407075
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
